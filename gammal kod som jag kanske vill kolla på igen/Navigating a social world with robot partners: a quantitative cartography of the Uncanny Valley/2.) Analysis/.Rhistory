# education
d2$educ = recode(d2$educ, " 1='a.No.HS'; 2='b.HS.only'; 3='c.2.Yr.Coll'; 4='d.4.Yr.Coll';
5='Post.Grad.Degree' ")
# race vars were originally checkboxes
# recode NAs as 0
race.vars = c("caucasian", "hisp", "black", "middle.east", "pacific.isl", "native.am",
"south.asian", "east.asian", "southeast.asian")
d2[,race.vars] = apply( d2[,race.vars], 2, function(x) recode(x, "NA=0") )
library(car)
install.packages("car")
summary(d2$caucasian)
dim(d2)
686/152
(686-152)/686]
(686-152)/686
install.packages('car', dependencies=TRUE, repos='http://cran.rstudio.com/')
setwd("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis/2. Prepped data/1B-1C")
l = read.csv("2015-06-17_expt_1B_likeability_long_prepped.csv"); dim(l)  # 5027
t = read.csv("2015-06-17_expt_1C_trust_long_prepped.csv"); dim(t)  # 4943
f = read.csv("2015-06-21_expt_1B_1C_face_means.csv"); dim(f)  # 80
###### Demographics #####
# take only first obs for likeability subject group
first.l = l[!duplicated(l$id),]; dim(first.l)
SummaryStats(first.l, n.cat=3)
setwd("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis/2. Prepped data/1B-1C")
library(lessR)
install.packages('lessR', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(lessR)
# take only first obs for likeability subject group
first.l = l[!duplicated(l$id),]; dim(first.l)
SummaryStats(first.l, n.cat=3)
head(first.l)
SummaryStats(first.l, n.cat=3)
dim(first.l)
head(first.l)
names(first.l)[8:16]
SummaryStats(first.l[8:16])
SummaryStats(first.l[8:16,])
fake = first.l[8:16,]
SummaryStats(fake)
head(fake)
SummaryStats(first.l[,8:16])
fake = first.l[,8:16]
head(fake)
SummaryStats(fake)
setwd("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis/2. Prepped data/1B-1C")
l = read.csv("2015-06-17_expt_1B_likeability_long_prepped.csv"); dim(l)  # 5027
t = read.csv("2015-06-17_expt_1C_trust_long_prepped.csv"); dim(t)  # 4943
f = read.csv("2015-06-21_expt_1B_1C_face_means.csv"); dim(f)  # 80
library(car)
library(lme4)
library(lmerTest)
library(Hmisc)
library(plotly)
library(lessR)
library(mediation)
# http://ww2.coastal.edu/kingw/statistics/R-tutorials/simplenonlinear.html
# poly regression on means data
rs0 = lm( f$like.mean ~ f$composite + I(f$composite^2), weights=1/(f$like.sd^2) ); summary(rs0)
?lm
l.mod.weighted = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3), weights=1/(f$like.sd^2) ); summary(l.mod.weighted)
rs2 = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3) + I(f$composite^4), weights=1/(f$like.sd^2) ); summary(rs2)
# compare three models for fit
anova(rs0, l.mod.weighted, rs2)
# third-order model is best
# http://ww2.coastal.edu/kingw/statistics/R-tutorials/simplenonlinear.html
# poly regression on means data
rs0 = lm( f$like.mean ~ f$composite + I(f$composite^2), weights=1/(f$like.sd^2) ); summary(rs0)
l.mod.weighted = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3), weights=1/(f$like.sd^2) ); summary(l.mod.weighted)
rs2 = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3) + I(f$composite^4), weights=1/(f$like.sd^2) ); summary(rs2)
# compare three models for fit
anova(rs0, l.mod.weighted, rs2)
# third-order model is best
################################## ONLY LOW-EMOTION FACES (DASHED LINE) ##################################
# weighted among only low-emotion faces
f2 = f[f$low.emot==TRUE,]
rs0 = lm( f2$like.mean ~ f2$composite + I(f2$composite^2), weights=1/(f2$like.sd^2) ); summary(rs0)
l.mod.weighted.low.emot = lm( f2$like.mean ~ f2$composite + I(f2$composite^2) +
I(f2$composite^3), weights=1/(f2$like.sd^2) ); summary(l.mod.weighted.low.emot)
rs2 = lm( f2$like.mean ~ f2$composite + I(f2$composite^2) +
I(f2$composite^3) + I(f2$composite^4), weights=1/(f2$like.sd^2) ); summary(rs2)
# compare three models for fit
anova(rs0, l.mod.weighted.low.emot, rs2)
# same
################################## SENSITIVITY: UNWEIGHTED ##################################
rs0 = lm( f$like.mean ~ f$composite + I(f$composite^2) ); summary(rs0)
l.mod.unweighted = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3) ); summary(l.mod.unweighted)
rs2 = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3) + I(f$composite^4) ); summary(rs2)
# compare three models for fit
anova(rs0, l.mod.unweighted, rs2)
# same
################################## DOES EMOTION MODERATE? ##################################
# does emotion moderate when treated as continuous?  (a priori)
l.emot.main = lm( f$like.mean ~ f$composite + f$mean.emot + I(f$composite^2) +
I(f$composite^3), weights=1/(f$like.sd^2) ); summary(l.emot.main)
l.emot.int = lm( f$like.mean ~ f$composite*f$mean.emot + I(f$composite^2)*f$mean.emot +
I(f$composite^3)*f$mean.emot, weights=1/(f$like.sd^2) ); summary(l.emot.int)
# does emotion moderate the Uncanny Valley? (test all 3 interaction terms simultaneously)
anova(l.emot.main, l.emot.int)
# does emotion moderate when dichotomized? (in response to reviewer)
l.emot.main = lm( f$like.mean ~ f$composite + f$low.emot + I(f$composite^2) +
I(f$composite^3), weights=1/(f$like.sd^2) ); summary(l.emot.main)
l.emot.int = lm( f$like.mean ~ f$composite*f$low.emot + I(f$composite^2)*f$low.emot +
I(f$composite^3)*f$low.emot, weights=1/(f$like.sd^2) ); summary(l.emot.int)
# does emotion moderate the Uncanny Valley? (test all 3 interaction terms simultaneously)
anova(l.emot.main, l.emot.int)
################################## SCATTERPLOT WITH FITTED CURVES ##################################
# fitted equations for 3 models
eq_w = function(x) {
model = l.mod.weighted
coef(model)[1] + coef(model)[2]*x + coef(model)[3]*(x^2) + coef(model)[4]*(x^3)
}
eq_uw = function(x) {
model = l.mod.unweighted
coef(model)[1] + coef(model)[2]*x + coef(model)[3]*(x^2) + coef(model)[4]*(x^3)
}
eq_w_low_emot = function(x) {
model = l.mod.weighted.low.emot
coef(model)[1] + coef(model)[2]*x + coef(model)[3]*(x^2) + coef(model)[4]*(x^3)
}
# get CI for the analysis model
fit = predict(l.mod.weighted, se.fit=TRUE)
predframe = data.frame("like.mean" = fit$fit, "lwr"=fit$fit-1.96*fit$se.fit,
"upr"=fit$fit+1.96*fit$se.fit, "composite"=f$composite)
xlab="Mechano-humanness score (-100 to 100)"
ylab="Likability (-100 to 100)"
shapes = c(45, 43)
p1 = ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes) +
theme(text = element_text(size=28) ) +
theme(legend.position="none")  # remove in order to see legend
p1
################################## SCATTERPLOT WITH FITTED CURVES ##################################
# fitted equations for 3 models
eq_w = function(x) {
model = l.mod.weighted
coef(model)[1] + coef(model)[2]*x + coef(model)[3]*(x^2) + coef(model)[4]*(x^3)
}
eq_uw = function(x) {
model = l.mod.unweighted
coef(model)[1] + coef(model)[2]*x + coef(model)[3]*(x^2) + coef(model)[4]*(x^3)
}
eq_w_low_emot = function(x) {
model = l.mod.weighted.low.emot
coef(model)[1] + coef(model)[2]*x + coef(model)[3]*(x^2) + coef(model)[4]*(x^3)
}
# get CI for the analysis model
fit = predict(l.mod.weighted, se.fit=TRUE)
predframe = data.frame("like.mean" = fit$fit, "lwr"=fit$fit-1.96*fit$se.fit,
"upr"=fit$fit+1.96*fit$se.fit, "composite"=f$composite)
xlab="Mechano-humanness score (-100 to 100)"
ylab="Likability (-100 to 100)"
shapes = c(45, 43)
p1 = ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes) +
theme(text = element_text(size=28) ) +
theme(legend.position="none")  # remove in order to see legend
p1 = ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes) +
#theme(text = element_text(size=28) ) +
theme(legend.position="none")  # remove in order to see legend
library(ggplot2)
p1 = ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes) +
theme(text = element_text(size=28) ) +
theme(legend.position="none")  # remove in order to see legend
# get CI for the analysis model
fit = predict(l.mod.weighted, se.fit=TRUE)
predframe = data.frame("like.mean" = fit$fit, "lwr"=fit$fit-1.96*fit$se.fit,
"upr"=fit$fit+1.96*fit$se.fit, "composite"=f$composite)
xlab="Mechano-humanness score (-100 to 100)"
ylab="Likability (-100 to 100)"
shapes = c(45, 43)
p1 = ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes) +
theme(text = element_text(size=28) ) +
theme(legend.position="none")  # remove in order to see legend
ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab)
ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab)
ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25))
ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes)
ggplot(f, aes(x=composite, y=like.mean) ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=7) +
geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="black", lwd=2.2) +  # weighted regression curve
#stat_function(fun=eq_uw, color="blue") +  # unweighted regression curve
#geom_smooth() +  # LOESS
stat_function(fun=eq_w_low_emot, color="black", lty=2, lwd=1) + # weighted regression curve, low emotion
geom_ribbon(data=predframe, aes(ymin=lwr, ymax=upr), alpha=0.1) +  # CI band for main analysis model
xlab(xlab) + ylab(ylab) +
scale_x_continuous(breaks=seq(-100, 100, 25)) +
scale_y_continuous(breaks=seq(-100, 100, 25)) +
#scale_color_manual(values=col, labels=labels, name="") +
scale_shape_manual(values=shapes) +
theme(text = element_text(size=28) )
optimize(eq_w, interval=c(-100, 100), maximum=TRUE)
optimize(eq_w, interval=c(-100, 100), maximum=FALSE)
optimize(eq_w, interval=c(70, 100), maximum=TRUE)
z = qnorm( 1 - .05/2 )
z
3600/2
optimize(eq_w, interval=c(-100, 100), maximum=TRUE)
setwd("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis/2. Prepped data/1B-1C")
l = read.csv("2015-06-17_expt_1B_likeability_long_prepped.csv"); dim(l)  # 5027
t = read.csv("2015-06-17_expt_1C_trust_long_prepped.csv"); dim(t)  # 4943
f = read.csv("2015-06-21_expt_1B_1C_face_means.csv"); dim(f)  # 80
library(car)
library(lme4)
library(lmerTest)
library(Hmisc)
library(plotly)
library(lessR)
library(mediation)
library(ggplot2)
# http://ww2.coastal.edu/kingw/statistics/R-tutorials/simplenonlinear.html
# poly regression on means data
rs0 = lm( f$like.mean ~ f$composite + I(f$composite^2), weights=1/(f$like.sd^2) ); summary(rs0)
l.mod.weighted = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3), weights=1/(f$like.sd^2) ); summary(l.mod.weighted)
rs2 = lm( f$like.mean ~ f$composite + I(f$composite^2) +
I(f$composite^3) + I(f$composite^4), weights=1/(f$like.sd^2) ); summary(rs2)
anova(rs0, l.mod.weighted, rs2)
##### Simplified Version for Graphical Abstract #####
xlab = ""
ylab="Likability"
half.width = 35
highlight = ifelse(f$face %in% c(76,4,79,66), "red", "black")  # 4 faces to highlight on graph
p3 = ggplot(f, aes(x=composite, y=like.mean, group=highlight) ) +
geom_rect( aes(xmin=uv.nadir-half.width, xmax=uv.nadir+half.width, ymin=-100, ymax=100),
fill="#ffeaa8", alpha=0.1 ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=4, color=highlight) +
#geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="red", lwd=3) +  # weighted regression curve
xlab(xlab) + ylab(ylab) +
#scale_y_continuous(breaks=seq(-100, 100, 10))
scale_x_continuous(breaks=NULL) +
scale_y_continuous(breaks=NULL) +
#scale_y_continuous(breaks=seq(-100, 100, 50)) +
theme(text = element_text(size=28) )
p3
ggplot(f, aes(x=composite, y=like.mean, group=highlight) ) +
geom_rect( aes(xmin=uv.nadir-half.width, xmax=uv.nadir+half.width, ymin=-100, ymax=100),
fill="#ffeaa8", alpha=0.1 ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=4, color=highlight) +
#geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="red", lwd=3) +  # weighted regression curve
xlab(xlab) + ylab(ylab) +
#scale_y_continuous(breaks=seq(-100, 100, 10))
scale_x_continuous(breaks=NULL) +
scale_y_continuous(breaks=NULL) +
#scale_y_continuous(breaks=seq(-100, 100, 50))
ggplot(f, aes(x=composite, y=like.mean, group=highlight) ) +
geom_rect( aes(xmin=uv.nadir-half.width, xmax=uv.nadir+half.width, ymin=-100, ymax=100),
fill="#ffeaa8", alpha=0.1 ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=4, color=highlight) +
#geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="red", lwd=3) +  # weighted regression curve
xlab(xlab) + ylab(ylab) +
#scale_y_continuous(breaks=seq(-100, 100, 10))
scale_x_continuous(breaks=NULL) +
scale_y_continuous(breaks=NULL)
ggplot(f, aes(x=composite, y=like.mean, group=highlight) ) +
geom_rect( aes(xmin=uv.nadir-half.width, xmax=uv.nadir+half.width, ymin=-100, ymax=100),
fill="#ffeaa8", alpha=0.1 ) +
#geom_hline(yintercept=0, color="gray", lwd=.6) +  # reference line for neutrality
geom_point(size=4, color=highlight) +
#geom_point(aes(shape=emot.valence), color="white", size=9 ) +
theme_bw() +
stat_function(fun=eq_w, color="red", lwd=3) +  # weighted regression curve
xlab(xlab) + ylab(ylab) +
#scale_y_continuous(breaks=seq(-100, 100, 10))
scale_x_continuous(breaks=NULL) +
scale_y_continuous(breaks=NULL)
optimize(eq_w, interval=c(-100, 100), maximum=TRUE)
optimize(eq_w, interval=c(-100, 100), maximum=FALSE)
optimize(eq_w, interval=c(70, 100), maximum=TRUE)
setwd("~/Dropbox/Uncanny Valley Projects II/2014-12-26 Re-analyses/TIME CAPSULE/Analysis materials/2. Prepped data/2A")
d = read.csv("2015-06-17_prepped_expt_2A_data.csv")
d = d[,-1]  # remove superfluous column
dim(d)  # 312 X 8
library(lme4)
library(lmerTest)
library(lsmeans)
library(ggplot2)
####################
# main analysis model
m = lmer( vas ~ robot + (1|id), data=d); summary(m)
red = lmer(vas ~ (1|id), data=d)
anova(m, red)
install.packages("lmerTest")
# main analysis model
m = lmer( vas ~ robot + (1|id), data=d); summary(m)
red = lmer(vas ~ (1|id), data=d)
anova(m, red)
setwd("~/Dropbox/Uncanny Valley Projects II/2014-12-26 Re-analyses/TIME CAPSULE/Analysis materials/2. Prepped data/2A")
d = read.csv("2015-06-17_prepped_expt_2A_data.csv")
d = d[,-1]  # remove superfluous column
dim(d)  # 312 X 8
library(lme4)
library(lmerTest)
library(lsmeans)
library(ggplot2)
################################# DESCRIPTIVE STATS #################################
# proportion male and robot owner
prop.table(table(d$male))
prop.table(table(d$own.robot))
# distribution of age is bimodal
ggplot(data=d, aes(x=age)) + geom_histogram()
hist(d$age)
mean(d$age)
median(d$age)
# mean rating by robot
aggregate(vas ~ robot, d, mean)
# 95% CI of ratings for best and worst faces
t.test(d$vas[d$robot=="f.Human"])
t.test(d$vas[d$robot=="d.K.bot"])
################################# MIXED MODELS #################################
# main analysis model
m = lmer( vas ~ robot + (1|id), data=d); summary(m)
red = lmer(vas ~ (1|id), data=d)
head(d)
dim(d)  # 312 X 8
d = read.csv("2015-06-17_prepped_expt_2A_data.csv")
list.files()
setwd("~/Dropbox/Uncanny Valley Projects II/2014-12-26 Re-analyses/TIME CAPSULE/Analysis materials/2. Prepped data/2A")
setwd("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis/2. Prepped data/2A")
setwd("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis/2. Prepped data/2A")
d = read.csv("2015-06-17_prepped_expt_2A_data.csv")
d = d[,-1]  # remove superfluous column
dim(d)  # 312 X 8
head(d)
################################# MIXED MODELS #################################
# main analysis model
m = lmer( vas ~ robot + (1|id), data=d); summary(m)
red = lmer(vas ~ (1|id), data=d)
anova(m, red)  # compare to reduced model without robot term
# pairwise comparisons of different robots
contrast( lsmeans(m, ~ robot), "pairwise" )
library(lme4)
library(lmerTest)
library(lsmeans)
library(ggplot2)
install.packages("lmerTest")
install.packages("lmerTest")
install.packages("lsmeans")
# full model - sensitivity analysis
m = lmer( vas ~ male + age + own.robot + robot + (1|id), data=d); summary(m)
red = lmer(vas ~ male + age + own.robot + (1|id), data=d)
anova(m, red)  # compare to reduced model without robot term
m = lmer( vas ~ robot + (1|id), data=d); summary(m)
red = lmer(vas ~ (1|id), data=d)
anova(m, red)  # compare to reduced model without robot term
# pairwise comparisons of different robots
contrast( lsmeans(m, ~ robot), "pairwise" )
library(lsmeans)
library(lsmeans)
m = lmer( vas ~ robot + (1|id), data=d); summary(m)
red = lmer(vas ~ (1|id), data=d)
anova(m, red)  # compare to reduced model without robot term
# pairwise comparisons of different robots
contrast( lsmeans(m, ~ robot), "pairwise" )
lib_dir <- tempfile()
dir.create(lib_dir)
devtools::install_github("mangothecat/pkgsnap", lib = lib_dir)
library(devtools)
install.packages("devtools")
lib_dir <- tempfile()
dir.create(lib_dir)
devtools::install_github("mangothecat/pkgsnap", lib = lib_dir)
install.packages("packrat")
devtools::install_github("rstudio/packrat")
snapshot()
packrat::snapshot()
packrat::init()
packrat::init("~/Dropbox/a.Uncanny Valley Projects II/2014-12-26 Re-analyses/Daz shared folder (UV)/TIME CAPSULE for OSF/2.) Analysis")
packrat::snapshot()
library(ggplot2)
packrat::snapshot()
packrat::bundle()
list.files()
snapshot <- tempfile()
snap(to = snapshot)
library(pkgsnap)
snapshot <- tempfile()
snap(to = snapshot)
snapshot
restore(snapshot)
